{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dattad\\Anaconda3\\lib\\site-packages\\pinecone\\index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone\n",
    "from tqdm import tqdm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinecone.init(api_key=\"\", environment=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pinecone-index']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone.list_indexes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\dattad\\\\Desktop\\\\pinecone-poc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dattad\\AppData\\Local\\Temp\\ipykernel_10644\\919608044.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"data/NYTFB-280K/train.txt\",sep = \"\\t\",header=1,names = [\"meta-1\",\"meta-2\",\"NE1\",\"NE2\",\"relation\",\"text\"])\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"data/NYTFB-280K/train.txt\",sep = \"\\t\",header=1,names = [\"meta-1\",\"meta-2\",\"NE1\",\"NE2\",\"relation\",\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_nas = data.dropna()\n",
    "dropped_nas[\"relation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dropped_nas[\"relation\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.replace(\"-lrb-\",\"\").replace(\"-rrb-\",\"\").replace(\"###END###\",\"\")\n",
    "    return text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropped_nas['cleaned_text'] = dropped_nas['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_dataset(df,category,MIN_SAMPLE_PER_GROUP,TARGET_SAMPLES):\n",
    "\n",
    "    small_groups = [group for _, group in df.groupby(category) if len(group) < MIN_SAMPLE_PER_GROUP]\n",
    "    large_groups = [group for _, group in df.groupby(category) if len(group) >= MIN_SAMPLE_PER_GROUP]\n",
    "    print(len(small_groups))\n",
    "    print(len(large_groups))\n",
    "\n",
    "    resampled_df = pd.concat(small_groups)\n",
    "    remaining_samples = TARGET_SAMPLES - len(resampled_df)\n",
    "    if remaining_samples > 0:\n",
    "        samples_per_large_group = remaining_samples // len(large_groups)\n",
    "        print(samples_per_large_group)\n",
    "        for group in large_groups:\n",
    "            print(\"--->\",len(group))\n",
    "            sampled_group = group.sample(n=samples_per_large_group, replace=False)\n",
    "            resampled_df = pd.concat([resampled_df, sampled_group])\n",
    "\n",
    "    resampled_df = resampled_df.reset_index(drop=True)\n",
    "    return resampled_df\n",
    "\n",
    "reduced_dataset = reduce_dataset(dropped_nas,\"relation\",400,10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = reduced_dataset[\"cleaned_text\"].tolist()\n",
    "\n",
    "embeddings= np.zeros((len(sentences),model.get_sentence_embedding_dimension()))\n",
    "\n",
    "for i in tqdm(range(len(sentences)),desc = \"Encoding Sentences\"):\n",
    "    embeddings[i] = model.encode([sentences[i]])\n",
    "\n",
    "reduced_dataset[\"embedding\"] = embeddings.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset.to_csv(\"reduced_dataset.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSERTING TO PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_name = \"pinecone-index\"\n",
    "# if index_name in pinecone.list_indexes():\n",
    "#     pinecone.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'meta-1', 'meta-2', 'NE1', 'NE2', 'relation', 'text',\n",
       "       'cleaned_text', 'embedding'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_metadata(df):\n",
    "    df[\"metadata\"] = df.apply(lambda x: {\"NE1\":x[\"NE1\"],\"NE2\":x[\"NE2\"],\"relation\":x[\"relation\"] },axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_dataset = create_metadata(reduced_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CREATING PINECONE UPSERT VECTORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectors(df):\n",
    "    df[\"pinecone-vectors\"] = df.apply(lambda x: (str(x[\"index\"]),x[\"embedding\"],x[\"metadata\"]),axis = 1)\n",
    "    return df\n",
    "\n",
    "reduced_dataset = create_vectors(reduced_dataset)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsert_vectors = reduced_dataset[\"pinecone-vectors\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'pinecone-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pinecone.create_index(index_name,dimension=384,metric=\"cosine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UPSERT TO PINECONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Upsert to the index with chunk size 500\n",
    "\n",
    "vector_num = 500\n",
    "\n",
    "for i in range(0,len(upsert_vectors),vector_num):\n",
    "    chunk = upsert_vectors[i:i+vector_num]\n",
    "    upsert_response = index.upsert(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USING PINECONE FOR FINDING SIMILARITY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NE1': 'wdet', 'NE2': 'detroit', 'relation': '/broadcast/content/location'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "upsert_vectors[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =100\n",
    "top_k = 15\n",
    "tuple_batches = [upsert_vectors[i:i+batch_size] for i in range(0,10000,batch_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name = 'pinecone-index'\n",
    "index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = index.query(top_k = 25,vector=upsert_vectors[0][1],include_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/business/company/major_shareholders': 10,\n",
       " '/business/company_shareholder/major_shareholder_of': 4,\n",
       " '/business/company/founders': 4,\n",
       " '/broadcast/content/location': 2,\n",
       " '/people/person/place_of_birth': 2,\n",
       " '/business/company/place_founded': 2,\n",
       " '/people/person/place_lived': 1}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(Counter([result[\"metadata\"][\"relation\"] for result in results[\"matches\"]]).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_liste = [result[\"metadata\"][\"relation\"] for result in results[\"matches\"]]\n",
    "text = \"\\n\".join(text_liste)\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/broadcast/content/location\\n/broadcast/content/location\\n/people/person/place_of_birth\\n/business/company/place_founded\\n/business/company/place_founded\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/founders\\n/people/person/place_lived\\n/business/company/founders\\n/business/company/founders\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/founders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/people/person/place_of_birth\\n/business/company/major_shareholders\\n/business/company/major_shareholders'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/broadcast/content/location\\n/broadcast/content/location\\n/people/person/place_of_birth\\n/business/company/place_founded\\n/business/company/place_founded\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/founders\\n/people/person/place_lived\\n/business/company/founders\\n/business/company/founders\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/founders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/business/company_shareholder/major_shareholder_of\\n/business/company/major_shareholders\\n/business/company/major_shareholders\\n/people/person/place_of_birth\\n/business/company/major_shareholders\\n/business/company/major_shareholders'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [06:40<00:00,  4.01s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "neighbours = defaultdict(set)\n",
    "threshold = 0.55\n",
    "index = pinecone.Index(index_name)\n",
    "\n",
    "for batch in tqdm(tuple_batches):\n",
    "    ids,vectors,_ = zip(*batch)\n",
    "    results = index.query(top_k = 25,queries=vectors)\n",
    "    for i,element in enumerate(results['results']):\n",
    "        # if element[\"score\"] > threshold:\n",
    "        neighbours[str(ids[i])].update([res['id'] for res in element[\"matches\"] if ((res['score'] > threshold) and (str(res['id']) != str(ids[i]) ))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbours_dict = {}\n",
    "neighbours_dict = dict(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('neigbours.pkl','wb') as f:\n",
    "    pickle.dump(dict(neighbours),f)\n",
    "\n",
    "with open('upsert_vectors.pkl','wb') as f:\n",
    "    pickle.dump(upsert_vectors,f)\n",
    "\n",
    "with open('reduced_dataset.pkl','wb') as f:\n",
    "    pickle.dump(reduced_dataset,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import openai\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_TYPE\"] = \"\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"\"\n",
    "EMBEDDING_DEPLOYED_NAME = \"\"\n",
    "EMBEDDING_MODEL_NAME = \"\"\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def get_embeddings(text):\n",
    "    embeddings =  OpenAIEmbeddings(\n",
    "    deployment=EMBEDDING_DEPLOYED_NAME,\n",
    "    model=EMBEDDING_MODEL_NAME)\n",
    "    response = openai.Embedding.create(\n",
    "            input=text,\n",
    "            engine=EMBEDDING_DEPLOYED_NAME,\n",
    "            deployment_id=EMBEDDING_DEPLOYED_NAME\n",
    "        \n",
    ")\n",
    "    return response['data'][0]['embedding']\n",
    "    # return embeddings.embed_query(text)\n",
    "\n",
    "\n",
    "# get_embeddings(\"hello\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARIZATION"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARIZE NEIGBHOURHOOLD\n",
    "THE VECTOR INDEX, EMBEDDING AND THE PINECONE INDEX ARE TO BE PASSED INTO THIS FUNCTION TO GET THE SUMMARY AND THE RELATIONS DICTIONARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('upsert_vectors.pkl','rb') as f:\n",
    "    upsert_vectors = pickle.load(f)\n",
    "with open('reduced_dataset.pkl','rb') as f:\n",
    "    reduced_dataset = pickle.load(f)\n",
    "with open('neigbours.pkl','rb') as f:\n",
    "    neighbours = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_neighbourhood(_id,_embed,_index,_engine = 'Davinci-1',_relations = 'relations',_sentence = 'sentence',_k = 15,_random_state = 42,_max_tokens = 100,prompt = 'What do the following texts have in common? Is there any common theme in these texts?'):\n",
    "    \n",
    "    if _index: \n",
    "        nns = _index.query(top_k=_k,\n",
    "                               vector = _embed,include_metadata=True)\n",
    "        \n",
    "        metadata_dict = dict(Counter([result[\"metadata\"][_relations] for result in results[\"matches\"]]).most_common())\n",
    "        text_liste = [result[\"metadata\"][_sentence] for result in results[\"matches\"]]\n",
    "        \n",
    "        text = \"\\n\".join(text_liste)\n",
    "\n",
    "        response = openai.Completion.create(\n",
    "            engine= _engine,\n",
    "            prompt=f'{prompt} \\n\"\"\"\\n{text}\\n\"\"\"\\n\\n Theme:',\n",
    "            temperature=0,\n",
    "            max_tokens=_max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        summary = \"Summary:\" + response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\")\n",
    "    else:\n",
    "        summary = 'Pinecone index not found'\n",
    "    \n",
    "    return summary,metadata_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.index.Index at 0x21af5b92790>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Summary: Locations and People Related to Companies The common theme in these texts is locations and people related to companies. This includes the location of a company's founding, the place of birth of its founders, the major shareholders, and the places where the founders have lived.\",\n",
       " {'/business/company/major_shareholders': 10,\n",
       "  '/business/company_shareholder/major_shareholder_of': 4,\n",
       "  '/business/company/founders': 4,\n",
       "  '/broadcast/content/location': 2,\n",
       "  '/people/person/place_of_birth': 2,\n",
       "  '/business/company/place_founded': 2,\n",
       "  '/people/person/place_lived': 1})"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_neighbourhood(_id = upsert_vectors[0][0],_embed = upsert_vectors[0][1],_index = index,_engine = 'Davinci-1',_relations = 'relation',_sentence = 'relation',_k = 15,_random_state = 42,_max_tokens = 100,prompt = 'What do the following texts have in common? Is there any common theme in these texts?')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dfs(_node, _cluster_id,_clusters,_neighbours):\n",
    "    stack = [_node]\n",
    "    while stack:\n",
    "        _node = stack.pop()\n",
    "        if _node not in _clusters:\n",
    "            _clusters[_node] = _cluster_id\n",
    "            stack.extend(_neighbours[_node] - set(_clusters.keys()))\n",
    "    return _clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clustering(_neighbours):\n",
    "    clusters = {}\n",
    "    cluster_id = 0\n",
    "\n",
    "    for index in _neighbours.keys():\n",
    "        if index not in clusters:\n",
    "            clusters = dfs(index, cluster_id,clusters,_neighbours)\n",
    "            cluster_id += 1\n",
    "\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = run_clustering(neighbours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "df = reduced_dataset.copy()\n",
    "df[\"index\"] = df[\"index\"].astype(str)\n",
    "df['cluster'] = df[\"index\"].map(clusters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_df = df.copy()\n",
    "\n",
    "def all_vs_topklabelling(df,column,k):\n",
    "    list_tuples = Counter(df[column]).most_common()[:k]\n",
    "    top_k_labels = [item[0] for item in list_tuples]\n",
    "    df[\"cluster_topk\"] = df[column].apply(lambda x: x if x in top_k_labels else \"-1\")\n",
    "    return df\n",
    "\n",
    "umap_df = all_vs_topklabelling(umap_df,\"cluster\",10)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUMMARIZE CLUSTERS"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THE BELOW FUNCTION IS FOR SUMMARIZING CLUSTERS (SAMPLES_PER_CLUSTER = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_clusters(_dataframe,_text_column_name,_cluster_column_name,_cluster_labels,_engine = 'Davinci-1',_samples_per_cluster = 15,_random_state = 42,_max_tokens = 100,prompt = 'What do the following texts have in common? Is there any common theme in these texts?'):\n",
    "    \n",
    "    output_dict = {\"Cluster_Num\" : [],\"Summary\" : []}\n",
    "    for i in _cluster_labels:\n",
    "        text = \"\\n\".join(\n",
    "            _dataframe[_dataframe[_cluster_column_name] == i][_text_column_name]\n",
    "            .sample(_samples_per_cluster, random_state = _random_state)\n",
    "            .values\n",
    "        )\n",
    "        response = openai.Completion.create(\n",
    "            engine= _engine,\n",
    "            prompt=f'{prompt} \\n\"\"\"\\n{text}\\n\"\"\"\\n\\n Theme:',\n",
    "            temperature=0,\n",
    "            max_tokens=_max_tokens,\n",
    "            top_p=1,\n",
    "            frequency_penalty=0,\n",
    "            presence_penalty=0,\n",
    "        )\n",
    "        output_dict[\"Cluster_Num\"].append(i)\n",
    "        output_dict[\"Summary\"].append(response[\"choices\"][0][\"text\"].replace(\"\\n\", \"\"))\n",
    "    return pd.DataFrame(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATAFRAME EXPECTED FOR the SUMMARIZE_CLUSTERS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>cluster_topk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr. coleman , the former deputy director , is ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it looked like that script was being followed ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>from a business standpoint , the cardinals did...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>from a business standpoint , the cardinals did...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>from a business standpoint , the cardinals did...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>a9 new hurdle for iraq constitution at least t...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>chabot in cincinnati will have a little more o...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>gates  village voice best of 2004  through wed...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>in his presentation in tokyo yesterday , ken_k...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>among those who came out to show their support...</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           cleaned_text cluster_topk\n",
       "0     mr. coleman , the former deputy director , is ...           -1\n",
       "1     it looked like that script was being followed ...           -1\n",
       "2     from a business standpoint , the cardinals did...           -1\n",
       "3     from a business standpoint , the cardinals did...           -1\n",
       "4     from a business standpoint , the cardinals did...           -1\n",
       "...                                                 ...          ...\n",
       "9995  a9 new hurdle for iraq constitution at least t...           -1\n",
       "9996  chabot in cincinnati will have a little more o...           -1\n",
       "9997  gates  village voice best of 2004  through wed...           -1\n",
       "9998  in his presentation in tokyo yesterday , ken_k...           -1\n",
       "9999  among those who came out to show their support...           99\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "umap_df[[\"cleaned_text\",\"cluster_topk\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = umap_df[\"cluster_topk\"].unique().tolist()[1:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESPONSE OF SUMMARIZE_CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cluster_Num</th>\n",
       "      <th>Summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>International Relations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>81</td>\n",
       "      <td>The common theme in these texts is the compan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>The common theme in these texts is the relati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>99</td>\n",
       "      <td>Politics and Government The common theme in t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>265</td>\n",
       "      <td>The common theme in these texts is the politi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>276</td>\n",
       "      <td>Death and memorials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>510</td>\n",
       "      <td>The texts have a common theme of the National...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>518</td>\n",
       "      <td>Football The common theme in these texts is f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>632</td>\n",
       "      <td>The common theme in these texts is the fashio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3486</td>\n",
       "      <td>The common theme in these texts is the story ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cluster_Num                                            Summary\n",
       "0           33                            International Relations\n",
       "1           81   The common theme in these texts is the compan...\n",
       "2           86   The common theme in these texts is the relati...\n",
       "3           99   Politics and Government The common theme in t...\n",
       "4          265   The common theme in these texts is the politi...\n",
       "5          276                                Death and memorials\n",
       "6          510   The texts have a common theme of the National...\n",
       "7          518   Football The common theme in these texts is f...\n",
       "8          632   The common theme in these texts is the fashio...\n",
       "9         3486   The common theme in these texts is the story ..."
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize_clusters(umap_df,\"cleaned_text\",\"cluster_topk\",cluster_labels,_samples_per_cluster = 15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
